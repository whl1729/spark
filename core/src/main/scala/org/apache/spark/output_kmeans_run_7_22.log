patching args=
Parsing conf: /usr/local/dragon/hiBench/conf/hadoop.conf
Parsing conf: /usr/local/dragon/hiBench/conf/hibench.conf
Parsing conf: /usr/local/dragon/hiBench/conf/spark.conf
Parsing conf: /usr/local/dragon/hiBench/conf/workloads/ml/kmeans.conf
probe sleep jar: /usr/local/dragon/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.8.1-tests.jar
start ScalaSparkKmeans bench
hdfs rm -r: /usr/local/dragon/hadoop/bin/hadoop --config /usr/local/dragon/hadoop/etc/hadoop fs -rm -r -skipTrash hdfs://master:9000/user/HiBench/Kmeans/Output
rm: `hdfs://master:9000/user/HiBench/Kmeans/Output': No such file or directory
hdfs du -s: /usr/local/dragon/hadoop/bin/hadoop --config /usr/local/dragon/hadoop/etc/hadoop fs -du -s hdfs://master:9000/user/HiBench/Kmeans/Input
Export env: SPARKBENCH_PROPERTIES_FILES=/usr/local/dragon/hiBench/report/kmeans/spark/conf/sparkbench/sparkbench.conf
Export env: HADOOP_CONF_DIR=/usr/local/dragon/hadoop/etc/hadoop
Submit Spark job: /usr/local/dragon/spark/bin/spark-submit  --properties-file /usr/local/dragon/hiBench/report/kmeans/spark/conf/sparkbench/spark.conf --class com.intel.hibench.sparkbench.ml.DenseKMeans --master yarn-client --num-executors 6 --executor-cores 8 --executor-memory 2g /usr/local/dragon/hiBench/sparkbench/assembly/target/sparkbench-assembly-7.1-SNAPSHOT-dist.jar -k 10 --numIterations 5 hdfs://master:9000/user/HiBench/Kmeans/Input/samples
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/dragon/spark/assembly/target/scala-2.11/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/dragon/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Warning: Master yarn-client is deprecated since 2.0. Please use master "yarn" with specified deploy mode instead.
18/07/22 10:32:19 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/07/22 10:32:19 INFO spark.SparkContext: Running Spark version 2.3.1
18/07/22 10:32:19 INFO spark.SparkContext: Submitted application: DenseKMeans with Params(hdfs://master:9000/user/HiBench/Kmeans/Input/samples,10,5,Parallel)
18/07/22 10:32:19 INFO spark.SecurityManager: Changing view acls to: root
18/07/22 10:32:19 INFO spark.SecurityManager: Changing modify acls to: root
18/07/22 10:32:19 INFO spark.SecurityManager: Changing view acls groups to: 
18/07/22 10:32:19 INFO spark.SecurityManager: Changing modify acls groups to: 
18/07/22 10:32:19 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/22 10:32:19 INFO util.Utils: Successfully started service 'sparkDriver' on port 42475.
18/07/22 10:32:19 INFO spark.SparkEnv: Registering MapOutputTracker
18/07/22 10:32:19 INFO spark.SparkEnv: Registering BlockManagerMaster
18/07/22 10:32:19 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/22 10:32:19 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/22 10:32:19 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-ac9c6878-28eb-4d03-bc3f-aec2c31ba184
18/07/22 10:32:19 INFO memory.MemoryStore: MemoryStore started with capacity 912.3 MB
18/07/22 10:32:19 INFO spark.SparkEnv: Registering OutputCommitCoordinator
18/07/22 10:32:19 INFO util.log: Logging initialized @2016ms
18/07/22 10:32:19 INFO server.Server: jetty-9.3.z-SNAPSHOT
18/07/22 10:32:19 INFO server.Server: Started @2101ms
18/07/22 10:32:19 INFO server.AbstractConnector: Started ServerConnector@674006e6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/07/22 10:32:19 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5bdaf2ce{/jobs,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@65e7f52a{/jobs/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@304b9f1a{/jobs/job,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@107e5441{/jobs/job/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4aeaadc1{/stages,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@263558c9{/stages/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f14f20c{/stages/stage,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6e4ea0bd{/stages/stage/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@56f2bbea{/stages/pool,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78f9ed3e{/stages/pool/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1059754c{/storage,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@b0964b2{/storage/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48e7b3d2{/storage/rdd,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f4037ed{/storage/rdd/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@24e8de5c{/environment,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@64040287{/environment/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@110844f6{/executors,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6f89f665{/executors/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@df1cff6{/executors/threadDump,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4925f4f5{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1ad926d3{/static,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@27494e46{/,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d59970a{/api,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7fcff1b9{/jobs/job/kill,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@697446d4{/stages/stage/kill,null,AVAILABLE,@Spark}
18/07/22 10:32:19 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://master:4040
18/07/22 10:32:19 INFO spark.SparkContext: Added JAR file:/usr/local/dragon/hiBench/sparkbench/assembly/target/sparkbench-assembly-7.1-SNAPSHOT-dist.jar at spark://master:42475/jars/sparkbench-assembly-7.1-SNAPSHOT-dist.jar with timestamp 1532269939982
18/07/22 10:32:20 INFO util.Utils: [along]sc: dynamicAllocation is Enabled.
18/07/22 10:32:20 INFO util.Utils: Using initial executors = 6, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
18/07/22 10:32:20 INFO client.RMProxy: Connecting to ResourceManager at master/192.168.1.199:8032
18/07/22 10:32:20 INFO yarn.Client: Requesting a new application from cluster with 8 NodeManagers
18/07/22 10:32:20 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (5120 MB per container)
18/07/22 10:32:20 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
18/07/22 10:32:20 INFO yarn.Client: Setting up container launch context for our AM
18/07/22 10:32:20 INFO yarn.Client: Setting up the launch environment for our AM container
18/07/22 10:32:20 INFO yarn.Client: Preparing resources for our AM container
18/07/22 10:32:21 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
18/07/22 10:32:23 INFO yarn.Client: Uploading resource file:/tmp/spark-2c5059e0-8e2c-428b-9090-171576e5f80f/__spark_libs__5498052541182280313.zip -> hdfs://master:9000/user/root/.sparkStaging/application_1532169035394_0011/__spark_libs__5498052541182280313.zip
18/07/22 10:32:24 INFO yarn.Client: Uploading resource file:/tmp/spark-2c5059e0-8e2c-428b-9090-171576e5f80f/__spark_conf__7456246267917524973.zip -> hdfs://master:9000/user/root/.sparkStaging/application_1532169035394_0011/__spark_conf__.zip
18/07/22 10:32:24 INFO spark.SecurityManager: Changing view acls to: root
18/07/22 10:32:24 INFO spark.SecurityManager: Changing modify acls to: root
18/07/22 10:32:24 INFO spark.SecurityManager: Changing view acls groups to: 
18/07/22 10:32:24 INFO spark.SecurityManager: Changing modify acls groups to: 
18/07/22 10:32:24 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
18/07/22 10:32:24 INFO yarn.Client: Submitting application application_1532169035394_0011 to ResourceManager
18/07/22 10:32:24 INFO impl.YarnClientImpl: Submitted application application_1532169035394_0011
18/07/22 10:32:24 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1532169035394_0011 and attemptId None
18/07/22 10:32:25 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:25 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: AM container is launched, waiting for AM container to Register with RM
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1532269944907
	 final status: UNDEFINED
	 tracking URL: http://master:8088/proxy/application_1532169035394_0011/
	 user: root
18/07/22 10:32:26 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:27 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:28 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:29 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:30 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:31 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:32 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:33 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:34 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:35 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:36 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:37 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:38 INFO spark.SparkContext: [along]0. there are 10 metrics data: 
18/07/22 10:32:38 INFO spark.SparkContext: 119194672
18/07/22 10:32:38 INFO spark.SparkContext: 73920264
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO spark.SparkContext: 149059
18/07/22 10:32:38 INFO spark.SparkContext: 0
18/07/22 10:32:38 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:39 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:40 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:41 INFO yarn.Client: Application report for application_1532169035394_0011 (state: ACCEPTED)
18/07/22 10:32:42 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> master, PROXY_URI_BASES -> http://master:8088/proxy/application_1532169035394_0011), /proxy/application_1532169035394_0011
18/07/22 10:32:42 INFO ui.JettyUtils: Adding filter: org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
18/07/22 10:32:42 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
18/07/22 10:32:42 INFO yarn.Client: Application report for application_1532169035394_0011 (state: RUNNING)
18/07/22 10:32:42 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 192.168.1.105
	 ApplicationMaster RPC port: 0
	 queue: default
	 start time: 1532269944907
	 final status: UNDEFINED
	 tracking URL: http://master:8088/proxy/application_1532169035394_0011/
	 user: root
18/07/22 10:32:42 INFO cluster.YarnClientSchedulerBackend: Application application_1532169035394_0011 has started running.
18/07/22 10:32:43 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38137.
18/07/22 10:32:43 INFO netty.NettyBlockTransferService: Server created on master:38137
18/07/22 10:32:43 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/22 10:32:43 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, master, 38137, None)
18/07/22 10:32:43 INFO storage.BlockManagerMasterEndpoint: Registering block manager master:38137 with 912.3 MB RAM, BlockManagerId(driver, master, 38137, None)
18/07/22 10:32:43 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, master, 38137, None)
18/07/22 10:32:43 INFO storage.BlockManager: external shuffle service port = 9337
18/07/22 10:32:43 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, master, 38137, None)
18/07/22 10:32:43 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@565d7d2f{/metrics/json,null,AVAILABLE,@Spark}
18/07/22 10:32:43 INFO util.Utils: [along]sc: dynamicAllocation is Enabled.
18/07/22 10:32:43 INFO util.Utils: Using initial executors = 6, max of spark.dynamicAllocation.initialExecutors, spark.dynamicAllocation.minExecutors and spark.executor.instances
18/07/22 10:32:46 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.199:57562) with ID 6
18/07/22 10:32:46 INFO spark.ExecutorAllocationManager: New executor 6 has registered (new total is 1)
18/07/22 10:32:46 INFO storage.BlockManagerMasterEndpoint: Registering block manager master:41793 with 912.3 MB RAM, BlockManagerId(6, master, 41793, None)
18/07/22 10:32:47 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.199:57568) with ID 14
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: New executor 14 has registered (new total is 2)
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: [along]eam_schedule: executor 6 is to be removed.
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: [along]eam_schedule: need to remove some execotors.
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: Request to remove executorIds: 6
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: [along]removeExecutors: numExistingExecs=2, execCountFloor=6, minNumExecutors=0, numExecutorsTarget=6, executorIdsToBeRemoved.size=1, dontRemove.size=0.
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: [along]removeExecutors: recoverCachedData.
18/07/22 10:32:47 INFO spark.ExecutorAllocationManager: Removing executors (6) because they have been idlefor 1 seconds
18/07/22 10:32:47 INFO spark.CacheRecoveryManager: [along]Recover cached data before shutting down executors 6.
18/07/22 10:32:47 INFO storage.BlockManagerMasterEndpoint: Registering block manager master:34495 with 912.3 MB RAM, BlockManagerId(14, master, 34495, None)
18/07/22 10:32:47 INFO spark.CacheRecoveryManager: [along]startCacheRecovery: executor 6 can be recovered.
18/07/22 10:32:47 INFO cluster.YarnClientSchedulerBackend: Requesting to kill executor(s) 6
18/07/22 10:32:47 INFO cluster.YarnClientSchedulerBackend: Actual list of executor(s) to be killed is 6
18/07/22 10:32:48 INFO spark.SparkContext: [along]1. there are 10 metrics data: 
18/07/22 10:32:48 INFO spark.SparkContext: 310399888
18/07/22 10:32:48 INFO spark.SparkContext: 80580256
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.SparkContext: 152033
18/07/22 10:32:48 INFO spark.SparkContext: 0
18/07/22 10:32:48 INFO spark.ExecutorAllocationManager: [along]eam_schedule: executor 14 is to be removed.
18/07/22 10:32:48 INFO spark.ExecutorAllocationManager: [along]eam_schedule: need to remove some execotors.
18/07/22 10:32:48 INFO spark.ExecutorAllocationManager: Request to remove executorIds: 14
18/07/22 10:32:48 INFO spark.ExecutorAllocationManager: [along]removeExecutors: numExistingExecs=1, execCountFloor=6, minNumExecutors=0, numExecutorsTarget=6, executorIdsToBeRemoved.size=0, dontRemove.size=1.
18/07/22 10:32:48 INFO spark.ExecutorAllocationManager: [along]removeExecutors: executorIdsToBeRemoved is empty.
18/07/22 10:32:49 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 6.
18/07/22 10:32:49 INFO scheduler.DAGScheduler: Executor lost: 6 (epoch 0)
18/07/22 10:32:49 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
18/07/22 10:32:49 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, master, 41793, None)
18/07/22 10:32:49 INFO storage.BlockManagerMaster: Removed 6 successfully in removeExecutor
18/07/22 10:32:49 ERROR cluster.YarnScheduler: Lost executor 6 on master: Container container_1532169035394_0011_01_000007 exited from explicit termination request.
18/07/22 10:32:49 INFO spark.ExecutorAllocationManager: Existing executor 6 has been removed (new total is 1)
18/07/22 10:32:50 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)
18/07/22 10:32:50 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 319.2 KB, free 912.0 MB)
18/07/22 10:32:50 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.7 KB, free 912.0 MB)
18/07/22 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on master:38137 (size: 27.7 KB, free: 912.3 MB)
18/07/22 10:32:50 INFO spark.SparkContext: Created broadcast 0 from sequenceFile at DenseKMeans.scala:86
18/07/22 10:32:50 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.1.199:57574) with ID 20
18/07/22 10:32:50 INFO mapred.FileInputFormat: Total input files to process : 5
18/07/22 10:32:50 INFO spark.ExecutorAllocationManager: New executor 20 has registered (new total is 2)
18/07/22 10:32:50 INFO spark.SparkContext: Starting job: count at DenseKMeans.scala:98
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Got job 0 (count at DenseKMeans.scala:98) with 5 output partitions
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (count at DenseKMeans.scala:98)
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at map at DenseKMeans.scala:88), which has no missing parents
18/07/22 10:32:50 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:50 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
[along]connect to MBean server and MXBean proxy.
18/07/22 10:32:50 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 3.7 KB, free 912.0 MB)
18/07/22 10:32:50 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.1 KB, free 912.0 MB)
18/07/22 10:32:50 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on master:38137 (size: 2.1 KB, free: 912.3 MB)
java.io.IOException: Failed to retrieve RMIServer stub: javax.naming.ServiceUnavailableException [Root exception is java.rmi.ConnectException: Connection refused to host: mbsrv; nested exception is: 
	java.net.ConnectException: Connection refused (Connection refused)]
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:369)
	at javax.management.remote.JMXConnectorFactory.connect(JMXConnectorFactory.java:270)
	at org.apache.spark.metrics.JVMCPUUsage.openMBeanServerConnection(JVMCPUUsage.java:55)
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:86)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
Caused by: javax.naming.ServiceUnavailableException [Root exception is java.rmi.ConnectException: Connection refused to host: mbsrv; nested exception is: 
	java.net.ConnectException: Connection refused (Connection refused)]
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:136)
	at com.sun.jndi.toolkit.url.GenericURLContext.lookup(GenericURLContext.java:205)
	at javax.naming.InitialContext.lookup(InitialContext.java:417)
	at javax.management.remote.rmi.RMIConnector.findRMIServerJNDI(RMIConnector.java:1955)
	at javax.management.remote.rmi.RMIConnector.findRMIServer(RMIConnector.java:1922)
	at javax.management.remote.rmi.RMIConnector.connect(RMIConnector.java:287)
	... 17 more
Caused by: java.rmi.ConnectException: Connection refused to host: mbsrv; nested exception is: 
	java.net.ConnectException: Connection refused (Connection refused)
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:619)
	at sun.rmi.transport.tcp.TCPChannel.createConnection(TCPChannel.java:216)
	at sun.rmi.transport.tcp.TCPChannel.newConnection(TCPChannel.java:202)
	at sun.rmi.server.UnicastRef.newCall(UnicastRef.java:338)
	at sun.rmi.registry.RegistryImpl_Stub.lookup(RegistryImpl_Stub.java:112)
	at com.sun.jndi.rmi.registry.RegistryContext.lookup(RegistryContext.java:132)
	... 22 more
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at java.net.Socket.connect(Socket.java:538)
	at java.net.Socket.<init>(Socket.java:434)
	at java.net.Socket.<init>(Socket.java:211)
	at sun.rmi.transport.proxy.RMIDirectSocketFactory.createSocket(RMIDirectSocketFactory.java:40)
	at sun.rmi.transport.proxy.RMIMasterSocketFactory.createSocket(RMIMasterSocketFactory.java:148)
	at sun.rmi.transport.tcp.TCPEndpoint.newSocket(TCPEndpoint.java:613)
	... 27 more
18/07/22 10:32:50 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:50 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:50 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at map at DenseKMeans.scala:88) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:50 INFO cluster.YarnScheduler: Adding task set 0.0 with 5 tasks
18/07/22 10:32:50 INFO storage.BlockManagerMasterEndpoint: Registering block manager master:36273 with 912.3 MB RAM, BlockManagerId(20, master, 36273, None)
18/07/22 10:32:50 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, master, executor 14, partition 0, NODE_LOCAL, 7921 bytes)
18/07/22 10:32:50 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, master, executor 20, partition 1, NODE_LOCAL, 7921 bytes)
18/07/22 10:32:50 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, master, executor 14, partition 2, NODE_LOCAL, 7921 bytes)
18/07/22 10:32:50 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, master, executor 20, partition 3, NODE_LOCAL, 7921 bytes)
18/07/22 10:32:50 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, master, executor 14, partition 4, NODE_LOCAL, 7921 bytes)
18/07/22 10:32:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on master:34495 (size: 2.1 KB, free: 912.3 MB)
18/07/22 10:32:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on master:34495 (size: 27.7 KB, free: 912.3 MB)
18/07/22 10:32:51 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on master:36273 (size: 2.1 KB, free: 912.3 MB)
18/07/22 10:32:51 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on master:36273 (size: 27.7 KB, free: 912.3 MB)
18/07/22 10:32:52 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on master:34495 (size: 351.6 KB, free: 911.9 MB)
18/07/22 10:32:52 INFO storage.BlockManagerInfo: Added rdd_2_2 in memory on master:34495 (size: 351.6 KB, free: 911.6 MB)
18/07/22 10:32:52 INFO storage.BlockManagerInfo: Added rdd_2_4 in memory on master:34495 (size: 351.6 KB, free: 911.2 MB)
18/07/22 10:32:52 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1991 ms on master (executor 14) (1/5)
18/07/22 10:32:52 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 1998 ms on master (executor 14) (2/5)
18/07/22 10:32:52 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2021 ms on master (executor 14) (3/5)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_2_3 in memory on master:36273 (size: 351.6 KB, free: 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_2_1 in memory on master:36273 (size: 351.6 KB, free: 911.6 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2339 ms on master (executor 20) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 2338 ms on master (executor 20) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 0 (count at DenseKMeans.scala:98) finished in 2.438 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 0 finished: count at DenseKMeans.scala:98, took 2.504499 s
numExamples = 30000.
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:354
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 1 (takeSample at KMeans.scala:354) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (takeSample at KMeans.scala:354)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at map at KMeans.scala:224), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.5 KB, free 912.0 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.5 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on master:38137 (size: 2.5 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at map at KMeans.scala:224) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 1.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 5, master, executor 20, partition 1, PROCESS_LOCAL, 8232 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 6, master, executor 14, partition 0, PROCESS_LOCAL, 8232 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 7, master, executor 20, partition 3, PROCESS_LOCAL, 8232 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 8, master, executor 14, partition 2, PROCESS_LOCAL, 8232 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, master, executor 14, partition 4, PROCESS_LOCAL, 8232 bytes)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on master:36273 (size: 2.5 KB, free: 911.6 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on master:34495 (size: 2.5 KB, free: 911.2 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_3_1 in memory on master:36273 (size: 46.9 KB, free: 911.5 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_3_3 in memory on master:36273 (size: 46.9 KB, free: 911.5 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_3_2 in memory on master:34495 (size: 46.9 KB, free: 911.2 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_3_4 in memory on master:34495 (size: 46.9 KB, free: 911.1 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_3_0 in memory on master:34495 (size: 46.9 KB, free: 911.1 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 6) in 154 ms on master (executor 14) (1/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 5) in 157 ms on master (executor 20) (2/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 7) in 155 ms on master (executor 20) (3/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 8) in 154 ms on master (executor 14) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 155 ms on master (executor 14) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 1 (takeSample at KMeans.scala:354) finished in 0.174 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 1 finished: takeSample at KMeans.scala:354, took 0.180257 s
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: takeSample at KMeans.scala:354
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 2 (takeSample at KMeans.scala:354) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (takeSample at KMeans.scala:354)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (PartitionwiseSampledRDD[7] at takeSample at KMeans.scala:354), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.3 KB, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on master:38137 (size: 2.9 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (PartitionwiseSampledRDD[7] at takeSample at KMeans.scala:354) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 2.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10, master, executor 20, partition 1, PROCESS_LOCAL, 8341 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 11, master, executor 14, partition 0, PROCESS_LOCAL, 8341 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12, master, executor 20, partition 3, PROCESS_LOCAL, 8341 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 2.0 (TID 13, master, executor 14, partition 2, PROCESS_LOCAL, 8341 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, master, executor 14, partition 4, PROCESS_LOCAL, 8341 bytes)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on master:36273 (size: 2.9 KB, free: 911.5 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on master:34495 (size: 2.9 KB, free: 911.1 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 62 ms on master (executor 20) (1/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 60 ms on master (executor 20) (2/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 2.0 (TID 13) in 69 ms on master (executor 14) (3/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 73 ms on master (executor 14) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 11) in 74 ms on master (executor 14) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 2 (takeSample at KMeans.scala:354) finished in 0.084 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 2 finished: takeSample at KMeans.scala:354, took 0.088829 s
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 144.0 B, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 356.0 B, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on master:38137 (size: 356.0 B, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 4 from broadcast at KMeans.scala:368
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: sum at KMeans.scala:374
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 3 (sum at KMeans.scala:374) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (sum at KMeans.scala:374)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[9] at map at KMeans.scala:371), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.4 KB, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.9 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on master:38137 (size: 2.9 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[9] at map at KMeans.scala:371) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 3.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 15, master, executor 20, partition 1, PROCESS_LOCAL, 8264 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16, master, executor 14, partition 0, PROCESS_LOCAL, 8264 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 3.0 (TID 17, master, executor 20, partition 3, PROCESS_LOCAL, 8264 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18, master, executor 14, partition 2, PROCESS_LOCAL, 8264 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, master, executor 14, partition 4, PROCESS_LOCAL, 8264 bytes)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on master:36273 (size: 2.9 KB, free: 911.5 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on master:34495 (size: 2.9 KB, free: 911.1 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on master:34495 (size: 356.0 B, free: 911.1 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on master:36273 (size: 356.0 B, free: 911.5 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_9_3 in memory on master:36273 (size: 46.9 KB, free: 911.4 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_9_1 in memory on master:36273 (size: 46.9 KB, free: 911.4 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_9_4 in memory on master:34495 (size: 46.9 KB, free: 911.0 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 3.0 (TID 17) in 128 ms on master (executor 20) (1/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 15) in 139 ms on master (executor 20) (2/5)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_9_2 in memory on master:34495 (size: 46.9 KB, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_9_0 in memory on master:34495 (size: 46.9 KB, free: 911.0 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 141 ms on master (executor 14) (3/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 145 ms on master (executor 14) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 16) in 148 ms on master (executor 14) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 3 (sum at KMeans.scala:374) finished in 0.158 s
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 3 finished: sum at KMeans.scala:374, took 0.163113 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO rdd.MapPartitionsRDD: Removing RDD 6 from persistence list
18/07/22 10:32:53 INFO storage.BlockManager: Removing RDD 6
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on master:34495 in memory (size: 356.0 B, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on master:36273 in memory (size: 356.0 B, free: 911.4 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: collect at KMeans.scala:382
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 4 (collect at KMeans.scala:382) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (collect at KMeans.scala:382)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[11] at mapPartitionsWithIndex at KMeans.scala:379), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.0 KB, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.2 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on master:38137 (size: 3.2 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[11] at mapPartitionsWithIndex at KMeans.scala:379) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 4.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, master, executor 14, partition 0, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, master, executor 20, partition 1, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, master, executor 14, partition 2, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, master, executor 20, partition 3, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, master, executor 14, partition 4, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on master:34495 (size: 3.2 KB, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on master:36273 (size: 3.2 KB, free: 911.4 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 45 ms on master (executor 14) (1/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 45 ms on master (executor 14) (2/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 44 ms on master (executor 14) (3/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 48 ms on master (executor 20) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 48 ms on master (executor 20) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 4 (collect at KMeans.scala:382) finished in 0.057 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 4 finished: collect at KMeans.scala:382, took 0.062000 s
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 1832.0 B, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1223.0 B, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on master:38137 (size: 1223.0 B, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 7 from broadcast at KMeans.scala:368
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: sum at KMeans.scala:374
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 5 (sum at KMeans.scala:374) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (sum at KMeans.scala:374)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[13] at map at KMeans.scala:371), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 5.6 KB, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.0 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on master:38137 (size: 3.0 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[13] at map at KMeans.scala:371) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 5.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 25, master, executor 20, partition 1, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 26, master, executor 14, partition 0, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 5.0 (TID 27, master, executor 20, partition 3, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 5.0 (TID 28, master, executor 14, partition 2, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, master, executor 14, partition 4, PROCESS_LOCAL, 8296 bytes)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on master:36273 (size: 3.0 KB, free: 911.4 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on master:34495 (size: 3.0 KB, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on master:36273 (size: 1223.0 B, free: 911.4 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on master:34495 (size: 1223.0 B, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_13_3 in memory on master:36273 (size: 46.9 KB, free: 911.3 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_13_1 in memory on master:36273 (size: 46.9 KB, free: 911.3 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_13_0 in memory on master:34495 (size: 46.9 KB, free: 910.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_13_4 in memory on master:34495 (size: 46.9 KB, free: 910.9 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 5.0 (TID 27) in 83 ms on master (executor 20) (1/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 26) in 84 ms on master (executor 14) (2/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 84 ms on master (executor 14) (3/5)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added rdd_13_2 in memory on master:34495 (size: 46.9 KB, free: 910.8 MB)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 25) in 90 ms on master (executor 20) (4/5)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 5.0 (TID 28) in 95 ms on master (executor 14) (5/5)
18/07/22 10:32:53 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/07/22 10:32:53 INFO scheduler.DAGScheduler: ResultStage 5 (sum at KMeans.scala:374) finished in 0.104 s
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Job 5 finished: sum at KMeans.scala:374, took 0.107471 s
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO rdd.MapPartitionsRDD: Removing RDD 9 from persistence list
18/07/22 10:32:53 INFO storage.BlockManager: Removing RDD 9
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on master:34495 in memory (size: 1223.0 B, free: 911.0 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on master:36273 in memory (size: 1223.0 B, free: 911.4 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Starting job: collect at KMeans.scala:382
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Got job 6 (collect at KMeans.scala:382) with 5 output partitions
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (collect at KMeans.scala:382)
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[15] at mapPartitionsWithIndex at KMeans.scala:379), which has no missing parents
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:53 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:53 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 6.3 KB, free 911.9 MB)
18/07/22 10:32:53 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KB, free 911.9 MB)
18/07/22 10:32:53 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on master:38137 (size: 3.3 KB, free: 912.3 MB)
18/07/22 10:32:53 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:53 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at mapPartitionsWithIndex at KMeans.scala:379) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:53 INFO cluster.YarnScheduler: Adding task set 6.0 with 5 tasks
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 30, master, executor 20, partition 1, PROCESS_LOCAL, 8328 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 31, master, executor 14, partition 0, PROCESS_LOCAL, 8328 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 6.0 (TID 32, master, executor 20, partition 3, PROCESS_LOCAL, 8328 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 6.0 (TID 33, master, executor 14, partition 2, PROCESS_LOCAL, 8328 bytes)
18/07/22 10:32:53 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 6.0 (TID 34, master, executor 14, partition 4, PROCESS_LOCAL, 8328 bytes)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on master:34495 (size: 3.3 KB, free: 910.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on master:36273 (size: 3.3 KB, free: 911.4 MB)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 6.0 (TID 33) in 23 ms on master (executor 14) (1/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 6.0 (TID 34) in 24 ms on master (executor 14) (2/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 31) in 25 ms on master (executor 14) (3/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 30) in 29 ms on master (executor 20) (4/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 6.0 (TID 32) in 28 ms on master (executor 20) (5/5)
18/07/22 10:32:54 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/07/22 10:32:54 INFO scheduler.DAGScheduler: ResultStage 6 (collect at KMeans.scala:382) finished in 0.037 s
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Job 6 finished: collect at KMeans.scala:382, took 0.041710 s
18/07/22 10:32:54 INFO rdd.MapPartitionsRDD: Removing RDD 13 from persistence list
18/07/22 10:32:54 INFO storage.BlockManager: Removing RDD 13
18/07/22 10:32:54 INFO broadcast.TorrentBroadcast: Destroying Broadcast(4) (from destroy at KMeans.scala:389)
18/07/22 10:32:54 INFO broadcast.TorrentBroadcast: Destroying Broadcast(7) (from destroy at KMeans.scala:389)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.0 KB, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.3 KB, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on master:38137 (size: 2.3 KB, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 10 from broadcast at KMeans.scala:399
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on master:38137 in memory (size: 356.0 B, free: 912.3 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on master:38137 in memory (size: 1223.0 B, free: 912.3 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Starting job: countByValue at KMeans.scala:400
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Registering RDD 18 (countByValue at KMeans.scala:400)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Got job 7 (countByValue at KMeans.scala:400) with 8 output partitions
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (countByValue at KMeans.scala:400)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 7)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[18] at countByValue at KMeans.scala:400), which has no missing parents
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 6.6 KB, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.6 KB, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on master:38137 (size: 3.6 KB, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[18] at countByValue at KMeans.scala:400) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:54 INFO cluster.YarnScheduler: Adding task set 7.0 with 5 tasks
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 35, master, executor 14, partition 0, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 36, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 7.0 (TID 37, master, executor 14, partition 2, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 7.0 (TID 38, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 7.0 (TID 39, master, executor 14, partition 4, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on master:36273 (size: 3.6 KB, free: 911.5 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on master:34495 (size: 3.6 KB, free: 911.1 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on master:34495 (size: 2.3 KB, free: 911.1 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on master:36273 (size: 2.3 KB, free: 911.5 MB)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 35) in 343 ms on master (executor 14) (1/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 7.0 (TID 39) in 341 ms on master (executor 14) (2/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 7.0 (TID 37) in 342 ms on master (executor 14) (3/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 7.0 (TID 38) in 352 ms on master (executor 20) (4/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 36) in 353 ms on master (executor 20) (5/5)
18/07/22 10:32:54 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/07/22 10:32:54 INFO scheduler.DAGScheduler: ShuffleMapStage 7 (countByValue at KMeans.scala:400) finished in 0.365 s
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:54 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:54 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 8)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (ShuffledRDD[19] at countByValue at KMeans.scala:400), which has no missing parents
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 3.2 KB, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 1984.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on master:38137 (size: 1984.0 B, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 8 (ShuffledRDD[19] at countByValue at KMeans.scala:400) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:54 INFO cluster.YarnScheduler: Adding task set 8.0 with 8 tasks
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 40, master, executor 20, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 41, master, executor 14, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 8.0 (TID 42, master, executor 20, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 8.0 (TID 43, master, executor 14, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 8.0 (TID 44, master, executor 20, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 8.0 (TID 45, master, executor 14, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 8.0 (TID 46, master, executor 20, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 8.0 (TID 47, master, executor 14, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on master:36273 (size: 1984.0 B, free: 911.5 MB)
18/07/22 10:32:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.1.199:57574
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on master:34495 (size: 1984.0 B, free: 911.1 MB)
18/07/22 10:32:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to 192.168.1.199:57568
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 8.0 (TID 44) in 117 ms on master (executor 20) (1/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 40) in 121 ms on master (executor 20) (2/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 8.0 (TID 42) in 119 ms on master (executor 20) (3/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 8.0 (TID 46) in 119 ms on master (executor 20) (4/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 8.0 (TID 45) in 158 ms on master (executor 14) (5/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 8.0 (TID 47) in 157 ms on master (executor 14) (6/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 41) in 164 ms on master (executor 14) (7/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 8.0 (TID 43) in 163 ms on master (executor 14) (8/8)
18/07/22 10:32:54 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool 
18/07/22 10:32:54 INFO scheduler.DAGScheduler: ResultStage 8 (countByValue at KMeans.scala:400) finished in 0.171 s
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Job 7 finished: countByValue at KMeans.scala:400, took 0.700647 s
18/07/22 10:32:54 INFO broadcast.TorrentBroadcast: Destroying Broadcast(10) (from destroy at KMeans.scala:402)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on master:38137 in memory (size: 2.3 KB, free: 912.2 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on master:34495 in memory (size: 2.3 KB, free: 911.1 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on master:36273 in memory (size: 2.3 KB, free: 911.5 MB)
18/07/22 10:32:54 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
18/07/22 10:32:54 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
18/07/22 10:32:54 INFO clustering.LocalKMeans: Local KMeans++ converged in 2 iterations.
18/07/22 10:32:54 INFO clustering.KMeans: Initialization with k-means|| took 1.585 seconds.
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 880.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 671.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on master:38137 (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 13 from broadcast at KMeans.scala:273
18/07/22 10:32:54 INFO spark.SparkContext: Starting job: collectAsMap at KMeans.scala:298
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Registering RDD 20 (mapPartitions at KMeans.scala:276)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Got job 8 (collectAsMap at KMeans.scala:298) with 8 output partitions
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (collectAsMap at KMeans.scala:298)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 9)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[20] at mapPartitions at KMeans.scala:276), which has no missing parents
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 6.2 KB, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on master:38137 (size: 3.4 KB, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[20] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:54 INFO cluster.YarnScheduler: Adding task set 9.0 with 5 tasks
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 9.0 (TID 48, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 49, master, executor 14, partition 0, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 9.0 (TID 50, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 9.0 (TID 51, master, executor 14, partition 2, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 9.0 (TID 52, master, executor 14, partition 4, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on master:34495 (size: 3.4 KB, free: 911.1 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on master:36273 (size: 3.4 KB, free: 911.5 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on master:36273 (size: 671.0 B, free: 911.5 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on master:34495 (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 9.0 (TID 50) in 57 ms on master (executor 20) (1/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 9.0 (TID 48) in 58 ms on master (executor 20) (2/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 9.0 (TID 52) in 63 ms on master (executor 14) (3/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 9.0 (TID 51) in 64 ms on master (executor 14) (4/5)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 49) in 65 ms on master (executor 14) (5/5)
18/07/22 10:32:54 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool 
18/07/22 10:32:54 INFO scheduler.DAGScheduler: ShuffleMapStage 9 (mapPartitions at KMeans.scala:276) finished in 0.074 s
18/07/22 10:32:54 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:54 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:54 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 10)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[22] at mapValues at KMeans.scala:295), which has no missing parents
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 3.2 KB, free 911.9 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 1883.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on master:38137 (size: 1883.0 B, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 10 (MapPartitionsRDD[22] at mapValues at KMeans.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:54 INFO cluster.YarnScheduler: Adding task set 10.0 with 8 tasks
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 53, master, executor 14, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 10.0 (TID 54, master, executor 20, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 10.0 (TID 55, master, executor 14, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 10.0 (TID 56, master, executor 20, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 10.0 (TID 57, master, executor 14, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 10.0 (TID 58, master, executor 20, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 10.0 (TID 59, master, executor 14, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 10.0 (TID 60, master, executor 20, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on master:36273 (size: 1883.0 B, free: 911.5 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on master:34495 (size: 1883.0 B, free: 911.1 MB)
18/07/22 10:32:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.199:57568
18/07/22 10:32:54 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to 192.168.1.199:57574
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 10.0 (TID 55) in 33 ms on master (executor 14) (1/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 10.0 (TID 59) in 32 ms on master (executor 14) (2/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 10.0 (TID 57) in 37 ms on master (executor 14) (3/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 53) in 37 ms on master (executor 14) (4/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 10.0 (TID 58) in 40 ms on master (executor 20) (5/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 10.0 (TID 56) in 49 ms on master (executor 20) (6/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 10.0 (TID 60) in 49 ms on master (executor 20) (7/8)
18/07/22 10:32:54 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 10.0 (TID 54) in 51 ms on master (executor 20) (8/8)
18/07/22 10:32:54 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool 
18/07/22 10:32:54 INFO scheduler.DAGScheduler: ResultStage 10 (collectAsMap at KMeans.scala:298) finished in 0.058 s
18/07/22 10:32:54 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:54 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:54 INFO scheduler.DAGScheduler: Job 8 finished: collectAsMap at KMeans.scala:298, took 0.138022 s
18/07/22 10:32:54 INFO broadcast.TorrentBroadcast: Destroying Broadcast(13) (from destroy at KMeans.scala:300)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on master:38137 in memory (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 880.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on master:34495 in memory (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on master:36273 in memory (size: 671.0 B, free: 911.5 MB)
18/07/22 10:32:54 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 668.0 B, free 911.9 MB)
18/07/22 10:32:54 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on master:38137 (size: 668.0 B, free: 912.2 MB)
18/07/22 10:32:54 INFO spark.SparkContext: Created broadcast 16 from broadcast at KMeans.scala:273
18/07/22 10:32:55 INFO spark.SparkContext: Starting job: collectAsMap at KMeans.scala:298
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Registering RDD 23 (mapPartitions at KMeans.scala:276)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Got job 9 (collectAsMap at KMeans.scala:298) with 8 output partitions
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 12 (collectAsMap at KMeans.scala:298)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 11)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[23] at mapPartitions at KMeans.scala:276), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 6.2 KB, free 911.9 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on master:38137 (size: 3.4 KB, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[23] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 11.0 with 5 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 61, master, executor 14, partition 0, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 11.0 (TID 62, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 11.0 (TID 63, master, executor 14, partition 2, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 11.0 (TID 64, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 11.0 (TID 65, master, executor 14, partition 4, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on master:36273 (size: 3.4 KB, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on master:34495 (size: 3.4 KB, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on master:36273 (size: 668.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on master:34495 (size: 668.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 11.0 (TID 63) in 47 ms on master (executor 14) (1/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 61) in 50 ms on master (executor 14) (2/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 11.0 (TID 65) in 50 ms on master (executor 14) (3/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 11.0 (TID 62) in 54 ms on master (executor 20) (4/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 11.0 (TID 64) in 55 ms on master (executor 20) (5/5)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 11.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ShuffleMapStage 11 (mapPartitions at KMeans.scala:276) finished in 0.063 s
18/07/22 10:32:55 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:55 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:55 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 12)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[25] at mapValues at KMeans.scala:295), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 3.2 KB, free 911.9 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1885.0 B, free 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on master:38137 (size: 1885.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 12 (MapPartitionsRDD[25] at mapValues at KMeans.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 12.0 with 8 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 12.0 (TID 66, master, executor 14, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 12.0 (TID 67, master, executor 20, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 12.0 (TID 68, master, executor 14, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 12.0 (TID 69, master, executor 20, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 12.0 (TID 70, master, executor 14, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 12.0 (TID 71, master, executor 20, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 12.0 (TID 72, master, executor 14, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 12.0 (TID 73, master, executor 20, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on master:34495 (size: 1885.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on master:36273 (size: 1885.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.1.199:57568
18/07/22 10:32:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 192.168.1.199:57574
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 12.0 (TID 72) in 30 ms on master (executor 14) (1/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 12.0 (TID 68) in 36 ms on master (executor 14) (2/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 12.0 (TID 70) in 39 ms on master (executor 14) (3/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 12.0 (TID 66) in 41 ms on master (executor 14) (4/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 12.0 (TID 73) in 44 ms on master (executor 20) (5/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 12.0 (TID 69) in 49 ms on master (executor 20) (6/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 12.0 (TID 71) in 50 ms on master (executor 20) (7/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 12.0 (TID 67) in 52 ms on master (executor 20) (8/8)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 12.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ResultStage 12 (collectAsMap at KMeans.scala:298) finished in 0.059 s
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Job 9 finished: collectAsMap at KMeans.scala:298, took 0.131319 s
18/07/22 10:32:55 INFO broadcast.TorrentBroadcast: Destroying Broadcast(16) (from destroy at KMeans.scala:300)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on master:38137 in memory (size: 668.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 880.0 B, free 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on master:34495 in memory (size: 668.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_16_piece0 on master:36273 in memory (size: 668.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 671.0 B, free 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on master:38137 (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 19 from broadcast at KMeans.scala:273
18/07/22 10:32:55 INFO spark.SparkContext: Starting job: collectAsMap at KMeans.scala:298
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Registering RDD 26 (mapPartitions at KMeans.scala:276)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Got job 10 (collectAsMap at KMeans.scala:298) with 8 output partitions
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 14 (collectAsMap at KMeans.scala:298)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 13)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[26] at mapPartitions at KMeans.scala:276), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 6.2 KB, free 911.9 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on master:38137 (size: 3.4 KB, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[26] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 13.0 with 5 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 13.0 (TID 74, master, executor 14, partition 0, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 13.0 (TID 75, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 13.0 (TID 76, master, executor 14, partition 2, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 13.0 (TID 77, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 13.0 (TID 78, master, executor 14, partition 4, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on master:34495 (size: 3.4 KB, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on master:36273 (size: 3.4 KB, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on master:34495 (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on master:36273 (size: 671.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 13.0 (TID 76) in 38 ms on master (executor 14) (1/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 13.0 (TID 78) in 38 ms on master (executor 14) (2/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 13.0 (TID 77) in 43 ms on master (executor 20) (3/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 13.0 (TID 74) in 44 ms on master (executor 14) (4/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 13.0 (TID 75) in 49 ms on master (executor 20) (5/5)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 13.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ShuffleMapStage 13 (mapPartitions at KMeans.scala:276) finished in 0.057 s
18/07/22 10:32:55 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:55 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 14)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[28] at mapValues at KMeans.scala:295), which has no missing parents
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.2 KB, free 911.8 MB)
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 1885.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on master:38137 (size: 1885.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 14 (MapPartitionsRDD[28] at mapValues at KMeans.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 14.0 with 8 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 14.0 (TID 79, master, executor 14, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 14.0 (TID 80, master, executor 20, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 14.0 (TID 81, master, executor 14, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 14.0 (TID 82, master, executor 20, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 14.0 (TID 83, master, executor 14, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 14.0 (TID 84, master, executor 20, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 14.0 (TID 85, master, executor 14, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 14.0 (TID 86, master, executor 20, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on master:36273 (size: 1885.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.1.199:57574
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on master:34495 (size: 1885.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 3 to 192.168.1.199:57568
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 14.0 (TID 81) in 37 ms on master (executor 14) (1/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 14.0 (TID 85) in 37 ms on master (executor 14) (2/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 14.0 (TID 83) in 54 ms on master (executor 14) (3/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 14.0 (TID 79) in 62 ms on master (executor 14) (4/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 14.0 (TID 86) in 69 ms on master (executor 20) (5/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 14.0 (TID 82) in 71 ms on master (executor 20) (6/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 14.0 (TID 80) in 71 ms on master (executor 20) (7/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 14.0 (TID 84) in 72 ms on master (executor 20) (8/8)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 14.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ResultStage 14 (collectAsMap at KMeans.scala:298) finished in 0.082 s
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Job 10 finished: collectAsMap at KMeans.scala:298, took 0.146524 s
18/07/22 10:32:55 INFO broadcast.TorrentBroadcast: Destroying Broadcast(19) (from destroy at KMeans.scala:300)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on master:38137 in memory (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_22 stored as values in memory (estimated size 880.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on master:34495 in memory (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_19_piece0 on master:36273 in memory (size: 671.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 671.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on master:38137 (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 22 from broadcast at KMeans.scala:273
18/07/22 10:32:55 INFO spark.SparkContext: Starting job: collectAsMap at KMeans.scala:298
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Registering RDD 29 (mapPartitions at KMeans.scala:276)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Got job 11 (collectAsMap at KMeans.scala:298) with 8 output partitions
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 16 (collectAsMap at KMeans.scala:298)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 15)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[29] at mapPartitions at KMeans.scala:276), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_23 stored as values in memory (estimated size 6.2 KB, free 911.8 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on master:38137 (size: 3.4 KB, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[29] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 15.0 with 5 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 15.0 (TID 87, master, executor 14, partition 0, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 15.0 (TID 88, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 15.0 (TID 89, master, executor 14, partition 2, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 15.0 (TID 90, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 15.0 (TID 91, master, executor 14, partition 4, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on master:34495 (size: 3.4 KB, free: 911.1 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_23_piece0 in memory on master:36273 (size: 3.4 KB, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on master:36273 (size: 671.0 B, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_22_piece0 in memory on master:34495 (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 15.0 (TID 88) in 98 ms on master (executor 20) (1/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 15.0 (TID 87) in 98 ms on master (executor 14) (2/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 15.0 (TID 89) in 98 ms on master (executor 14) (3/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 15.0 (TID 90) in 98 ms on master (executor 20) (4/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 15.0 (TID 91) in 101 ms on master (executor 14) (5/5)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 15.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ShuffleMapStage 15 (mapPartitions at KMeans.scala:276) finished in 0.116 s
18/07/22 10:32:55 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:55 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 16)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[31] at mapValues at KMeans.scala:295), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted: stageId=15.
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]we're going to kill executor 14 among executor 
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_24 stored as values in memory (estimated size 3.2 KB, free 911.8 MB)
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: 20 
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: 14 
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: Request to remove executorIds: 14
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]removeExecutors: numExistingExecs=2, execCountFloor=6, minNumExecutors=0, numExecutorsTarget=6, executorIdsToBeRemoved.size=1, dontRemove.size=0.
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]removeExecutors: recoverCachedData.
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1885.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on master:38137 (size: 1885.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 16 (MapPartitionsRDD[31] at mapValues at KMeans.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 16.0 with 8 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 16.0 (TID 92, master, executor 20, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 16.0 (TID 93, master, executor 20, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 16.0 (TID 94, master, executor 20, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 16.0 (TID 95, master, executor 20, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 16.0 (TID 96, master, executor 20, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 16.0 (TID 97, master, executor 20, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 16.0 (TID 98, master, executor 20, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 16.0 (TID 99, master, executor 20, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: Removing executors (14) because they have been idlefor 1 seconds
18/07/22 10:32:55 INFO spark.CacheRecoveryManager: [along]Recover cached data before shutting down executors 14.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO spark.CacheRecoveryManager: [along]startCacheRecovery: executor 14 can be recovered.
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_24_piece0 in memory on master:36273 (size: 1885.0 B, free: 911.4 MB)
18/07/22 10:32:55 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 4 to 192.168.1.199:57574
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 16.0 (TID 96) in 43 ms on master (executor 20) (1/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 16.0 (TID 94) in 50 ms on master (executor 20) (2/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 16.0 (TID 99) in 50 ms on master (executor 20) (3/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 16.0 (TID 95) in 50 ms on master (executor 20) (4/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 16.0 (TID 97) in 54 ms on master (executor 20) (5/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 16.0 (TID 98) in 54 ms on master (executor 20) (6/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 16.0 (TID 93) in 58 ms on master (executor 20) (7/8)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 16.0 (TID 92) in 59 ms on master (executor 20) (8/8)
18/07/22 10:32:55 INFO cluster.YarnScheduler: Removed TaskSet 16.0, whose tasks have all completed, from pool 
18/07/22 10:32:55 INFO scheduler.DAGScheduler: ResultStage 16 (collectAsMap at KMeans.scala:298) finished in 0.066 s
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Job 11 finished: collectAsMap at KMeans.scala:298, took 0.188266 s
18/07/22 10:32:55 INFO broadcast.TorrentBroadcast: Destroying Broadcast(22) (from destroy at KMeans.scala:300)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on master:38137 in memory (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_25 stored as values in memory (estimated size 880.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on master:36273 in memory (size: 671.0 B, free: 911.4 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 671.0 B, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on master:38137 (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 25 from broadcast at KMeans.scala:273
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_3_4 in memory on master:36273 (size: 46.9 KB, free: 911.4 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Starting job: collectAsMap at KMeans.scala:298
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Registering RDD 32 (mapPartitions at KMeans.scala:276)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Got job 12 (collectAsMap at KMeans.scala:298) with 8 output partitions
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Final stage: ResultStage 18 (collectAsMap at KMeans.scala:298)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 17)
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276), which has no missing parents
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed broadcast_22_piece0 on master:34495 in memory (size: 671.0 B, free: 911.1 MB)
18/07/22 10:32:55 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:55 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_3_4 on master:34495 in memory (size: 46.9 KB, free: 911.1 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_26 stored as values in memory (estimated size 6.2 KB, free 911.8 MB)
18/07/22 10:32:55 INFO memory.MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.4 KB, free 911.8 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on master:38137 (size: 3.4 KB, free: 912.2 MB)
18/07/22 10:32:55 INFO spark.SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:55 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[32] at mapPartitions at KMeans.scala:276) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:55 INFO cluster.YarnScheduler: Adding task set 17.0 with 5 tasks
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 17.0 (TID 100, master, executor 20, partition 1, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 17.0 (TID 101, master, executor 20, partition 3, PROCESS_LOCAL, 8221 bytes)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_26_piece0 in memory on master:36273 (size: 3.4 KB, free: 911.4 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added broadcast_25_piece0 in memory on master:36273 (size: 671.0 B, free: 911.4 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_3_0 in memory on master:36273 (size: 46.9 KB, free: 911.4 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_3_0 on master:34495 in memory (size: 46.9 KB, free: 911.2 MB)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 17.0 (TID 101) in 65 ms on master (executor 20) (1/5)
18/07/22 10:32:55 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 17.0 (TID 100) in 65 ms on master (executor 20) (2/5)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_3_2 in memory on master:36273 (size: 46.9 KB, free: 911.3 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_3_2 on master:34495 in memory (size: 46.9 KB, free: 911.2 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_2_0 in memory on master:36273 (size: 351.6 KB, free: 911.0 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_2_0 on master:34495 in memory (size: 351.6 KB, free: 911.5 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_2_4 in memory on master:36273 (size: 351.6 KB, free: 910.6 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_2_4 on master:34495 in memory (size: 351.6 KB, free: 911.9 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Added rdd_2_2 in memory on master:36273 (size: 351.6 KB, free: 910.3 MB)
18/07/22 10:32:55 INFO storage.BlockManagerInfo: Removed rdd_2_2 on master:34495 in memory (size: 351.6 KB, free: 912.2 MB)
18/07/22 10:32:55 INFO cluster.YarnClientSchedulerBackend: Requesting to kill executor(s) 14
18/07/22 10:32:55 INFO cluster.YarnClientSchedulerBackend: Actual list of executor(s) to be killed is 14
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]eam_schedule: executor 14 is to be removed.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]eam_schedule: need to remove some execotors.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: Request to remove executorIds: 14
18/07/22 10:32:56 WARN spark.ExecutorAllocationManager: Attempted to remove executor 14 when it is already pending to be removed!
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]removeExecutors: numExistingExecs=1, execCountFloor=6, minNumExecutors=0, numExecutorsTarget=6, executorIdsToBeRemoved.size=0, dontRemove.size=0.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]removeExecutors: executorIdsToBeRemoved is empty.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]eam_schedule: executor 20 is to be removed.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]eam_schedule: need to remove some execotors.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: Request to remove executorIds: 20
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]removeExecutors: numExistingExecs=1, execCountFloor=6, minNumExecutors=0, numExecutorsTarget=6, executorIdsToBeRemoved.size=0, dontRemove.size=1.
18/07/22 10:32:56 INFO spark.ExecutorAllocationManager: [along]removeExecutors: executorIdsToBeRemoved is empty.
18/07/22 10:32:58 INFO spark.SparkContext: [along]0. there are 10 metrics data: 
18/07/22 10:32:58 INFO spark.SparkContext: 608629664
18/07/22 10:32:58 INFO spark.SparkContext: 103627608
18/07/22 10:32:58 INFO spark.SparkContext: 0
18/07/22 10:32:58 INFO spark.SparkContext: 0
18/07/22 10:32:58 INFO spark.SparkContext: 500498
18/07/22 10:32:58 INFO spark.SparkContext: 0
18/07/22 10:32:58 INFO spark.SparkContext: 500498
18/07/22 10:32:58 INFO spark.SparkContext: 0
18/07/22 10:32:58 INFO spark.SparkContext: 72729
18/07/22 10:32:58 INFO spark.SparkContext: 0
18/07/22 10:32:58 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 17.0 (TID 102, master, executor 20, partition 0, NODE_LOCAL, 8221 bytes)
18/07/22 10:32:58 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 17.0 (TID 103, master, executor 20, partition 2, NODE_LOCAL, 8221 bytes)
18/07/22 10:32:58 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 17.0 (TID 104, master, executor 20, partition 4, NODE_LOCAL, 8221 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 17.0 (TID 102) in 250 ms on master (executor 20) (3/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 17.0 (TID 103) in 249 ms on master (executor 20) (4/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 17.0 (TID 104) in 250 ms on master (executor 20) (5/5)
18/07/22 10:32:59 INFO cluster.YarnScheduler: Removed TaskSet 17.0, whose tasks have all completed, from pool 
18/07/22 10:32:59 INFO scheduler.DAGScheduler: ShuffleMapStage 17 (mapPartitions at KMeans.scala:276) finished in 3.623 s
18/07/22 10:32:59 INFO scheduler.DAGScheduler: looking for newly runnable stages
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:59 INFO scheduler.DAGScheduler: running: Set()
18/07/22 10:32:59 INFO scheduler.DAGScheduler: waiting: Set(ResultStage 18)
18/07/22 10:32:59 INFO scheduler.DAGScheduler: failed: Set()
18/07/22 10:32:59 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[34] at mapValues at KMeans.scala:295), which has no missing parents
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:59 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_27 stored as values in memory (estimated size 3.2 KB, free 911.8 MB)
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 1882.0 B, free 911.8 MB)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on master:38137 (size: 1882.0 B, free: 912.2 MB)
18/07/22 10:32:59 INFO spark.SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Submitting 8 missing tasks from ResultStage 18 (MapPartitionsRDD[34] at mapValues at KMeans.scala:295) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))
18/07/22 10:32:59 INFO cluster.YarnScheduler: Adding task set 18.0 with 8 tasks
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 18.0 (TID 105, master, executor 20, partition 0, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 18.0 (TID 106, master, executor 20, partition 1, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 18.0 (TID 107, master, executor 20, partition 2, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 18.0 (TID 108, master, executor 20, partition 3, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 18.0 (TID 109, master, executor 20, partition 4, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 18.0 (TID 110, master, executor 20, partition 5, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 18.0 (TID 111, master, executor 20, partition 6, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 18.0 (TID 112, master, executor 20, partition 7, NODE_LOCAL, 7660 bytes)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_27_piece0 in memory on master:36273 (size: 1882.0 B, free: 910.3 MB)
18/07/22 10:32:59 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 5 to 192.168.1.199:57574
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 18.0 (TID 107) in 22 ms on master (executor 20) (1/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 18.0 (TID 108) in 23 ms on master (executor 20) (2/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 18.0 (TID 111) in 22 ms on master (executor 20) (3/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 18.0 (TID 109) in 22 ms on master (executor 20) (4/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 18.0 (TID 112) in 23 ms on master (executor 20) (5/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 18.0 (TID 106) in 24 ms on master (executor 20) (6/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 18.0 (TID 105) in 24 ms on master (executor 20) (7/8)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 18.0 (TID 110) in 31 ms on master (executor 20) (8/8)
18/07/22 10:32:59 INFO cluster.YarnScheduler: Removed TaskSet 18.0, whose tasks have all completed, from pool 
18/07/22 10:32:59 INFO scheduler.DAGScheduler: ResultStage 18 (collectAsMap at KMeans.scala:298) finished in 0.041 s
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:59 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Job 12 finished: collectAsMap at KMeans.scala:298, took 3.672110 s
18/07/22 10:32:59 INFO broadcast.TorrentBroadcast: Destroying Broadcast(25) (from destroy at KMeans.scala:300)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on master:38137 in memory (size: 671.0 B, free: 912.2 MB)
18/07/22 10:32:59 INFO clustering.KMeans: Iterations took 4.416 seconds.
18/07/22 10:32:59 INFO clustering.KMeans: KMeans reached the max number of iterations: 5.
18/07/22 10:32:59 INFO clustering.KMeans: The cost is 2.0158922331547913E8.
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Removed broadcast_25_piece0 on master:36273 in memory (size: 671.0 B, free: 910.3 MB)
18/07/22 10:32:59 INFO rdd.MapPartitionsRDD: Removing RDD 3 from persistence list
18/07/22 10:32:59 INFO storage.BlockManager: Removing RDD 3
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_28 stored as values in memory (estimated size 880.0 B, free 911.8 MB)
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 664.0 B, free 911.8 MB)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on master:38137 (size: 664.0 B, free: 912.2 MB)
18/07/22 10:32:59 INFO spark.SparkContext: Created broadcast 28 from broadcast at KMeansModel.scala:87
18/07/22 10:32:59 INFO spark.SparkContext: Starting job: sum at KMeansModel.scala:89
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Got job 13 (sum at KMeansModel.scala:89) with 5 output partitions
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Final stage: ResultStage 19 (sum at KMeansModel.scala:89)
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Parents of final stage: List()
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Missing parents: List()
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[35] at map at KMeansModel.scala:89), which has no missing parents
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]onStageSubmitted...
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]start calculating cpu usage.
18/07/22 10:32:59 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.startCalcJvmCpuUsage(JVMCPUUsage.java:97)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageSubmitted(ExecutorAllocationManager.scala:699)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:33)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_29 stored as values in memory (estimated size 4.4 KB, free 911.8 MB)
18/07/22 10:32:59 INFO memory.MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 2.6 KB, free 911.8 MB)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on master:38137 (size: 2.6 KB, free: 912.2 MB)
18/07/22 10:32:59 INFO spark.SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1042
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Submitting 5 missing tasks from ResultStage 19 (MapPartitionsRDD[35] at map at KMeansModel.scala:89) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
18/07/22 10:32:59 INFO cluster.YarnScheduler: Adding task set 19.0 with 5 tasks
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 19.0 (TID 113, master, executor 20, partition 0, PROCESS_LOCAL, 7921 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 19.0 (TID 114, master, executor 20, partition 1, PROCESS_LOCAL, 7921 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 19.0 (TID 115, master, executor 20, partition 2, PROCESS_LOCAL, 7921 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 19.0 (TID 116, master, executor 20, partition 3, PROCESS_LOCAL, 7921 bytes)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 19.0 (TID 117, master, executor 20, partition 4, PROCESS_LOCAL, 7921 bytes)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_29_piece0 in memory on master:36273 (size: 2.6 KB, free: 910.5 MB)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Added broadcast_28_piece0 in memory on master:36273 (size: 664.0 B, free: 910.5 MB)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 19.0 (TID 113) in 33 ms on master (executor 20) (1/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 19.0 (TID 117) in 31 ms on master (executor 20) (2/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 19.0 (TID 116) in 33 ms on master (executor 20) (3/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 19.0 (TID 115) in 33 ms on master (executor 20) (4/5)
18/07/22 10:32:59 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 19.0 (TID 114) in 34 ms on master (executor 20) (5/5)
18/07/22 10:32:59 INFO cluster.YarnScheduler: Removed TaskSet 19.0, whose tasks have all completed, from pool 
18/07/22 10:32:59 INFO scheduler.DAGScheduler: ResultStage 19 (sum at KMeansModel.scala:89) finished in 0.042 s
18/07/22 10:32:59 INFO spark.ExecutorAllocationManager: [along]onStageCompleted...
18/07/22 10:32:59 ERROR scheduler.AsyncEventQueue: Listener ExecutorAllocationListener threw an exception
java.lang.NullPointerException
	at org.apache.spark.metrics.JVMCPUUsage.getJvmCpuUsage(JVMCPUUsage.java:105)
	at org.apache.spark.ExecutorAllocationManager$ExecutorAllocationListener.onStageCompleted(ExecutorAllocationManager.scala:740)
	at org.apache.spark.scheduler.SparkListenerBus$class.doPostEvent(SparkListenerBus.scala:35)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.scheduler.AsyncEventQueue.doPostEvent(AsyncEventQueue.scala:37)
	at org.apache.spark.util.ListenerBus$class.postToAll(ListenerBus.scala:91)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$super$postToAll(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply$mcJ$sp(AsyncEventQueue.scala:92)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anonfun$org$apache$spark$scheduler$AsyncEventQueue$$dispatch$1.apply(AsyncEventQueue.scala:87)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.scheduler.AsyncEventQueue.org$apache$spark$scheduler$AsyncEventQueue$$dispatch(AsyncEventQueue.scala:87)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1$$anonfun$run$1.apply$mcV$sp(AsyncEventQueue.scala:83)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1322)
	at org.apache.spark.scheduler.AsyncEventQueue$$anon$1.run(AsyncEventQueue.scala:82)
18/07/22 10:32:59 INFO scheduler.DAGScheduler: Job 13 finished: sum at KMeansModel.scala:89, took 0.044402 s
18/07/22 10:32:59 INFO broadcast.TorrentBroadcast: Destroying Broadcast(28) (from destroy at KMeansModel.scala:90)
Total cost = 2.0110452640085667E8.
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on master:38137 in memory (size: 664.0 B, free: 912.2 MB)
18/07/22 10:32:59 INFO storage.BlockManagerInfo: Removed broadcast_28_piece0 on master:36273 in memory (size: 664.0 B, free: 910.5 MB)
18/07/22 10:32:59 INFO server.AbstractConnector: Stopped Spark@674006e6{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
18/07/22 10:32:59 INFO ui.SparkUI: Stopped Spark web UI at http://master:4040
18/07/22 10:32:59 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread
18/07/22 10:32:59 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors
18/07/22 10:32:59 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down
18/07/22 10:32:59 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices
(serviceOption=None,
 services=List(),
 started=false)
18/07/22 10:32:59 INFO cluster.YarnClientSchedulerBackend: Stopped
18/07/22 10:32:59 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/22 10:32:59 INFO memory.MemoryStore: MemoryStore cleared
18/07/22 10:32:59 INFO storage.BlockManager: BlockManager stopped
18/07/22 10:32:59 INFO storage.BlockManagerMaster: BlockManagerMaster stopped
18/07/22 10:32:59 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/22 10:32:59 INFO spark.SparkContext: Successfully stopped SparkContext
18/07/22 10:32:59 INFO util.ShutdownHookManager: Shutdown hook called
18/07/22 10:32:59 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-2c5059e0-8e2c-428b-9090-171576e5f80f
18/07/22 10:32:59 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-e918ae8f-4d28-467a-90ff-df12f79e2817
finish ScalaSparkKmeans bench
